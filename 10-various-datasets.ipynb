{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import prepare_mnist, prepare_fashion_mnist, prepare_sub_mnist\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "writer = SummaryWriter(\"runs/autoencoder_clipping02\")\n",
    "\n",
    "from models import MNISTConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import dataclasses\n",
    "conf = MNISTConf(\n",
    "    batch_size=128,\n",
    "    n_hid=1000,\n",
    "    n_vis=784,\n",
    "    lr=0.01,\n",
    "    n_epoch=30,\n",
    "    optimizer=\"rmsprop\",\n",
    "    dataset=\"fashion_mnist\",\n",
    "    model_name=\"autoencoder\",\n",
    "    whitening_vis=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "conf.device = device\n",
    "print(\"device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf.dataset == \"mnist\":\n",
    "    train_datasets, train_loader, test_datasets, test_loader = prepare_mnist(batch_size=conf.batch_size)\n",
    "if conf.dataset == \"fashion_mnist\":\n",
    "    train_datasets, train_loader, test_datasets, test_loader = prepare_fashion_mnist(batch_size=conf.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def zca_whitening_matrix(X):\n",
    "    \"\"\"\n",
    "    Function to compute ZCA whitening matrix (aka Mahalanobis whitening).\n",
    "    INPUT:  X: [N x M] matrix.\n",
    "        Rows: Variables\n",
    "        Columns: Observations\n",
    "    OUTPUT: ZCAMatrix: [M x M] matrix\n",
    "    \"\"\"\n",
    "    # Covariance matrix [column-wise variables]: Sigma = (X-mu)' * (X-mu) / N\n",
    "    sigma = np.cov(X.T, rowvar=True) # [M x M]\n",
    "    # Singular Value Decomposition. X = U * np.diag(S) * V\n",
    "    U,S,V = np.linalg.svd(sigma)\n",
    "        # U: [M x M] eigenvectors of sigma.\n",
    "        # S: [M x 1] eigenvalues of sigma.\n",
    "        # V: [M x M] transpose of U\n",
    "    # Whitening constant: prevents division by zero\n",
    "    epsilon = 1e-10\n",
    "    # ZCA Whitening matrix: U * Lambda * U'\n",
    "    ZCAMatrix = np.dot(U, np.dot(np.diag(1.0/np.sqrt(S + epsilon)), U.T)) # [M x M]\n",
    "    return ZCAMatrix\n",
    "\n",
    "data = train_datasets.data.view(-1, conf.n_vis).numpy()\n",
    "P = zca_whitening_matrix(data)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(data[0].reshape(28, 28))\n",
    "\n",
    "plt.imshow(np.dot(data, P).reshape((-1, 28, 28))[0])\n",
    "data_white = np.dot(data, P).reshape((-1, conf.n_vis))\n",
    "data_white.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import AutoEncoder, RBM, MLPAutoEncoder, VAE\n",
    "\n",
    "def generate_vv(model, conf, fast=False):\n",
    "    for epoch in tqdm(range(conf.n_epoch)):\n",
    "        vv = np.zeros((len(train_datasets), conf.n_hid))\n",
    "        if fast:\n",
    "            for idx, (data, target) in enumerate(train_loader):\n",
    "                batch_size = data.size(0)\n",
    "                n_iter = len(train_loader) * epoch + idx\n",
    "                recon_loss = model.train_step(data.to(conf.device)).to(\"cpu\")\n",
    "                writer.add_scalar(f\"{model.__class__.__name__}/{str(conf)}/recon_loss\", recon_loss, n_iter)\n",
    "                vv[idx*batch_size:(idx+1)*batch_size, :] = model.encode(data.view(-1, conf.n_vis).to(conf.device)).detach().cpu().numpy()\n",
    "        else:\n",
    "            for idx, (data, target) in enumerate(train_loader):\n",
    "                if conf.whitening_vis:\n",
    "                    batch_size = data.size(0)\n",
    "                    n_iter = len(train_loader) * epoch\n",
    "                    batch_white = np.dot(data.view(batch_size, -1).numpy(), P)\n",
    "                    batch_white = torch.from_numpy(batch_white.astype(np.float32)).clone().view(batch_size, -1)\n",
    "                    vv[idx*batch_size:(idx+1)*batch_size, :] = model.encode(batch_white.to(conf.device)).detach().cpu().numpy()\n",
    "                    \n",
    "                else:\n",
    "                    batch_size = data.size(0)\n",
    "                    n_iter = len(train_loader) * epoch\n",
    "                    vv[idx*batch_size:(idx+1)*batch_size, :] = model.encode(data.view(-1, conf.n_vis).to(conf.device)).detach().cpu().numpy()\n",
    "            for idx, (data, target) in enumerate(train_loader):\n",
    "                if conf.whitening_learn:\n",
    "                    batch_size = data.size(0)\n",
    "                    n_step = len(train_loader) * epoch + idx\n",
    "                    batch_white = np.dot(data.view(batch_size, -1).numpy(), P)\n",
    "                    batch_white = torch.from_numpy(batch_white.astype(np.float32)).clone().view(batch_size, -1)\n",
    "                    loss = model.train_step(batch_white.to(conf.device)).cpu()\n",
    "                    writer.add_scalar(f\"{model.__class__.__name__}/{str(conf)}/loss\", loss, n_step)\n",
    "                    recon_loss = model.recon_loss(batch_white.to(device)).cpu()\n",
    "                    writer.add_scalar(f\"{model.__class__.__name__}/{str(conf)}/recon_loss\", recon_loss, n_step)  \n",
    "\n",
    "\n",
    "                else:\n",
    "                    batch_size = data.size(0)\n",
    "                    n_step = len(train_loader) * epoch + idx\n",
    "                    loss = model.train_step(data.to(device)).cpu()\n",
    "                    writer.add_scalar(f\"{model.__class__.__name__}/{str(conf)}/loss\", loss, n_step)\n",
    "                    recon_loss = model.recon_loss(data.to(device)).cpu()\n",
    "                    writer.add_scalar(f\"{model.__class__.__name__}/{str(conf)}/recon_loss\", recon_loss, n_step)       \n",
    "        n_nan = np.sum(np.isnan(vv))\n",
    "        if n_nan > 0:\n",
    "            raise ValueError(f\"vv contains {n_nan} NaN values.\")         \n",
    "        yield epoch, n_iter, vv\n",
    "    \n",
    "if conf.model_name == \"rbm\":\n",
    "    model = RBM(conf=conf).to(conf.device)\n",
    "elif conf.model_name == \"autoencoder\":\n",
    "    model = AutoEncoder(conf).to(conf.device)\n",
    "elif conf.model_name == \"vae\":\n",
    "    model = VAE(conf).to(conf.device)\n",
    "vv_iter = generate_vv(model, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [05:05<11:53, 33.97s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1826318/556189051.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvv_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1826318/3419017970.py\u001b[0m in \u001b[0;36mgenerate_vv\u001b[0;34m(model, conf, fast)\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mbatch_white\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0mbatch_white\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_white\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     \u001b[0mvv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_white\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "if not conf.whitening_learn:\n",
    "    sample_images = next(iter(test_loader))[0]\n",
    "else:\n",
    "    sample_images = next(iter(test_loader))[0]\n",
    "    sample_images = np.dot(sample_images.numpy().reshape(-1, conf.n_vis), P)\n",
    "    sample_images = torch.from_numpy(sample_images.astype(np.float32)).clone()\n",
    "\n",
    "\n",
    "sample_img = make_grid(sample_images.view(conf.batch_size, 1, 28, 28).data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "divider = make_axes_locatable(ax)\n",
    "mappable = cm.ScalarMappable(cmap=cm.viridis, norm=matplotlib.colors.Normalize(vmin=0, vmax=conf.n_epoch))\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(mappable=mappable,cax=cax, label=\"Epoch\")\n",
    "\n",
    "\n",
    "xx = np.arange(conf.n_hid) + 1\n",
    "log_xx = np.log(xx)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel('N')\n",
    "ax.set_ylabel('Variance')\n",
    "ax.grid(visible=True)\n",
    "labels = []\n",
    "\n",
    "#############################\n",
    "# Clipping the figures\n",
    "ax.set_ylim((10 ** (-6), 1)) \n",
    "#############################\n",
    "\n",
    "for n_epoch, n_iter, vv in vv_iter:\n",
    "    pca = PCA()\n",
    "    pca.fit(vv)\n",
    "    yy = pca.explained_variance_\n",
    "    log_yy = np.log(yy)\n",
    "    m, c = np.linalg.lstsq(np.vstack([log_xx, np.ones(len(log_xx))]).T, log_yy, rcond=None)[0]\n",
    "    pcm = ax.plot(xx, yy, '.-', color=cm.viridis(n_epoch / conf.n_epoch))\n",
    "\n",
    "\n",
    "\n",
    "    label = f\"{str(conf)}/neuron_fireings\"\n",
    "    writer.add_figure(label, fig, global_step=n_epoch)\n",
    "    labels.append(label)\n",
    "    \n",
    "\n",
    "    v_recon = model(sample_images.view(conf.batch_size, -1).to(device))\n",
    "    sample_recon = make_grid(v_recon.view(conf.batch_size, 1, 28, 28).data).cpu()\n",
    "    writer.add_image(f\"{str(conf)}/sample_input\", sample_img, global_step=n_epoch)\n",
    "    writer.add_image(f\"{str(conf)}/sample_recon\", sample_recon, global_step=n_epoch)\n",
    "\n",
    "    cum_var = pca.explained_variance_ratio_.cumsum()\n",
    "    ef_dim = np.argmax(np.where(cum_var < 0.99, cum_var, 0))\n",
    "    writer.add_scalar(f\"{str(conf)}/effective_dim\", ef_dim, global_step=n_epoch)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_var = pca.explained_variance_ratio_.cumsum()\n",
    "th = 0.99\n",
    "x_max = np.argmax(np.where(cum_var < th, cum_var, 0))\n",
    "print(\"x_max\", x_max)\n",
    "x_th =  np.arange(x_max) + 1\n",
    "y_th = pca.explained_variance_[:x_max]\n",
    "log_x_th = np.log(x_th)\n",
    "log_y_th = np.log(y_th)\n",
    "m, c = np.linalg.lstsq(np.vstack([log_x_th, np.ones(len(log_x_th))]).T, log_y_th, rcond=None)[0]\n",
    "\n",
    "xx = np.arange(conf.n_hid) + 1\n",
    "ax.plot(xx, np.e**c * xx**m, \"--\", c=\"magenta\", label=f\"Fitting to 99% of variance\")\n",
    "ax.scatter([x_max], [np.e**c * x_max**m], c=\"red\", marker=\"o\", linewidths=3, label=f\"a, n_max: {m:.3}, {x_max}\", zorder=2.5)\n",
    "ax.grid(visible=True)\n",
    "ax.legend()\n",
    "\n",
    "writer.add_figure(f\"{str(conf)}/neuron_fireings/finish\", fig)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "xx = np.arange(conf.n_hid) + 1\n",
    "log_xx = np.log(xx)\n",
    "\n",
    "ax.set_xlabel('Neurons')\n",
    "ax.set_ylabel('Variance explained')\n",
    "pca = PCA()\n",
    "pca.fit(vv)\n",
    "yy = pca.explained_variance_\n",
    "log_yy = np.log(yy)\n",
    "m, c = np.linalg.lstsq(np.vstack([log_xx, np.ones(len(log_xx))]).T, log_yy, rcond=None)[0]\n",
    "ax.plot(xx, yy,'.-', label=f\"epoch: {conf.n_epoch}\")\n",
    "ax.plot(xx, np.e**c * xx**m, label=f\"log y= {m:.3} log x + {c:.3}\")\n",
    "ax.legend()\n",
    "ax.set_ylim(0, np.max(yy))\n",
    "ax.grid(visible=True)\n",
    "writer.add_figure(f\"{model.__class__.__name__}/{str(conf)}/result/nonlog\", fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plfit\n",
    "\n",
    "myplfit = plfit.plfit(yy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some plots\n",
    "from pylab import *\n",
    "figure(1)\n",
    "myplfit.plotpdf()\n",
    "\n",
    "figure(2)\n",
    "myplfit.plotcdf()\n",
    "\n",
    "figure(3)\n",
    "myplfit.alphavsks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vv = np.zeros((len(test_datasets), conf.n_hid))\n",
    "vvlabel = np.zeros(len(test_datasets), dtype=np.int32)\n",
    "dataimg = np.zeros((len(test_datasets), conf.n_vis))\n",
    "\n",
    "for idx, (data, target) in enumerate(test_loader):\n",
    "    batch_size = data.size(0)\n",
    "    vv[idx*batch_size:(idx+1)*batch_size, :] = model.encode(data.view(-1, conf.n_vis).to(device)).detach().cpu().numpy()\n",
    "    vvlabel[idx*batch_size:(idx+1)*batch_size] = target\n",
    "    dataimg[idx*batch_size:(idx+1)*batch_size, :] = data.view(batch_size, -1)\n",
    "\n",
    "dataimg = torch.from_numpy(dataimg.reshape(-1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_embedding(vv, metadata=vvlabel, label_img=dataimg, tag=f\"{model.__class__.__name__}/{str(conf)}/projector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(train_datasets.data.view(-1, 784).numpy())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "xx = np.arange(len(pca.explained_variance_)) + 1\n",
    "ax.plot(xx, pca.explained_variance_, '.-')\n",
    "\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Neurons')\n",
    "ax.set_ylabel('Variance explained')\n",
    "log_xx = np.log(xx)\n",
    "yy = pca.explained_variance_\n",
    "log_yy = np.log(yy)\n",
    "m, c = np.linalg.lstsq(np.vstack([log_xx, np.ones(len(log_xx))]).T, log_yy, rcond=None)[0]\n",
    "ax.set_title(f'y=mx+c, m={m}, c={c}')\n",
    "ax.plot(xx, np.e**c * xx**m, label=f\"log y= {m:.3} log x + {c:.3}\")\n",
    "ax.grid()\n",
    "#ax.set_ylim(10 ** (-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plfit\n",
    "\n",
    "myplfit = plfit.plfit(yy)\n",
    "from pylab import *\n",
    "figure(1)\n",
    "myplfit.plotpdf()\n",
    "\n",
    "figure(2)\n",
    "myplfit.plotcdf()\n",
    "\n",
    "figure(3)\n",
    "myplfit.alphavsks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(data_white)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "xx = np.arange(len(pca.explained_variance_)) + 1\n",
    "ax.plot(xx, pca.explained_variance_, '.-')\n",
    "\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Neurons')\n",
    "ax.set_ylabel('Variance explained')\n",
    "log_xx = np.log(xx)\n",
    "yy = pca.explained_variance_\n",
    "log_yy = np.log(yy)\n",
    "m, c = np.linalg.lstsq(np.vstack([log_xx, np.ones(len(log_xx))]).T, log_yy, rcond=None)[0]\n",
    "ax.set_title(f'y=mx+c, m={m}, c={c}')\n",
    "ax.plot(xx, np.e**c * xx**m, label=f\"log y= {m:.3} log x + {c:.3}\")\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(data_white)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "xx = np.arange(conf.n_vis) + 1\n",
    "\n",
    "\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Neurons')\n",
    "ax.set_ylabel('Variance explained')\n",
    "log_xx = np.log(xx)\n",
    "yy = pca.explained_variance_\n",
    "log_yy = np.log(yy)\n",
    "m, c = np.linalg.lstsq(np.vstack([log_xx, np.ones(len(log_xx))]).T, log_yy, rcond=None)[0]\n",
    "ax.plot(xx, np.exp(-xx*2))\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25554aa828a01445f449ceb07a62b018f5dc6eacf1fdadcd1881e8950d47054e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
