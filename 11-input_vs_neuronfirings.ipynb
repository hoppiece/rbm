{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models import prepare_mnist, prepare_fashion_mnist, prepare_cifar10\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "from models import ModelConf\n",
    "writer=SummaryWriter(f\"CIFAR-10\")\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"device:\", device)\n",
    "conf = ModelConf(\n",
    "    batch_size=128,\n",
    "    n_hid=32*32,\n",
    "    n_vis=32*32,\n",
    "    n_epoch=10,\n",
    "    dataset=\"cifar10\",\n",
    "    model_name=\"rbm\",\n",
    "    optimizer=\"adam\"\n",
    ")\n",
    "conf.device = device\n",
    "\n",
    "train_datasets, train_loader, test_datasets, test_loader = prepare_cifar10(batch_size=conf.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import AutoEncoder, RBM, MLPAutoEncoder, VAE\n",
    "\n",
    "def generate_vv(model, conf, fast=False):\n",
    "    for epoch in tqdm(range(conf.n_epoch)):\n",
    "        vv = np.zeros((len(train_datasets), conf.n_hid))\n",
    "        if fast:\n",
    "            for idx, (data, target) in enumerate(train_loader):\n",
    "                batch_size = data.size(0)\n",
    "                n_iter = len(train_loader) * epoch + idx\n",
    "                recon_loss = model.train_step(data.to(conf.device)).to(\"cpu\")\n",
    "                writer.add_scalar(f\"{model.__class__.__name__}/{str(conf)}/recon_loss\", recon_loss, n_iter)\n",
    "                vv[idx*batch_size:(idx+1)*batch_size, :] = model.encode(data.view(-1, conf.n_vis).to(conf.device)).detach().cpu().numpy()\n",
    "        else:\n",
    "            for idx, (data, target) in enumerate(train_loader):\n",
    "                if conf.whitening_vis:\n",
    "                    batch_size = data.size(0)\n",
    "                    n_iter = len(train_loader) * epoch\n",
    "                    batch_white = np.dot(data.view(batch_size, -1).numpy(), P)\n",
    "                    batch_white = torch.from_numpy(batch_white.astype(np.float32)).clone().view(batch_size, -1)\n",
    "                    vv[idx*batch_size:(idx+1)*batch_size, :] = model.encode(batch_white.to(conf.device)).detach().cpu().numpy()\n",
    "                    \n",
    "                else:\n",
    "                    batch_size = data.size(0)\n",
    "                    n_iter = len(train_loader) * epoch\n",
    "                    vv[idx*batch_size:(idx+1)*batch_size, :] = model.encode(data.view(-1, conf.n_vis).to(conf.device)).detach().cpu().numpy()\n",
    "            for idx, (data, target) in enumerate(train_loader):\n",
    "                if conf.whitening_learn:\n",
    "                    batch_size = data.size(0)\n",
    "                    n_step = len(train_loader) * epoch + idx\n",
    "                    batch_white = np.dot(data.view(batch_size, -1).numpy(), P)\n",
    "                    batch_white = torch.from_numpy(batch_white.astype(np.float32)).clone().view(batch_size, -1)\n",
    "                    loss = model.train_step(batch_white.to(conf.device)).cpu()\n",
    "                    writer.add_scalar(f\"{model.__class__.__name__}/{str(conf)}/loss\", loss, n_step)\n",
    "                    recon_loss = model.recon_loss(batch_white.to(device)).cpu()\n",
    "                    writer.add_scalar(f\"{model.__class__.__name__}/{str(conf)}/recon_loss\", recon_loss, n_step)  \n",
    "\n",
    "\n",
    "                else:\n",
    "                    batch_size = data.size(0)\n",
    "                    n_step = len(train_loader) * epoch + idx\n",
    "                    loss = model.train_step(data.to(device)).cpu()\n",
    "                    writer.add_scalar(f\"{model.__class__.__name__}/{str(conf)}/loss\", loss, n_step)\n",
    "                    recon_loss = model.recon_loss(data.to(device)).cpu()\n",
    "                    writer.add_scalar(f\"{model.__class__.__name__}/{str(conf)}/recon_loss\", recon_loss, n_step)                \n",
    "        yield epoch, n_iter, vv\n",
    "    \n",
    "model = AutoEncoder(conf).to(device)\n",
    "vv_iter = generate_vv(model, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[128, 3, 32, 32]' is invalid for input of size 131072",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_454924/3496270257.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0msample_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[128, 3, 32, 32]' is invalid for input of size 131072"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "if not conf.whitening_learn:\n",
    "    sample_images = next(iter(test_loader))[0]\n",
    "else:\n",
    "    sample_images = next(iter(test_loader))[0]\n",
    "    sample_images = np.dot(sample_images.numpy().reshape(-1, conf.n_vis), P)\n",
    "    sample_images = torch.from_numpy(sample_images.astype(np.float32)).clone()\n",
    "\n",
    "\n",
    "sample_img = make_grid(sample_images.view(conf.batch_size, 1, 32, 32).data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "divider = make_axes_locatable(ax)\n",
    "mappable = cm.ScalarMappable(cmap=cm.viridis, norm=matplotlib.colors.Normalize(vmin=0, vmax=conf.n_epoch))\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(mappable=mappable,cax=cax, label=\"Epoch\")\n",
    "\n",
    "\n",
    "xx = np.arange(conf.n_hid) + 1\n",
    "log_xx = np.log(xx)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel('Neurons')\n",
    "ax.set_ylabel('Variance explained')\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(train_datasets.data.reshape(-1, conf.n_vis))\n",
    "yy = pca.explained_variance_\n",
    "log_yy = np.log(yy)\n",
    "m, c = np.linalg.lstsq(np.vstack([log_xx, np.ones(len(log_xx))]).T, log_yy, rcond=None)[0]\n",
    "ax.plot(xx, yy, label=\"Input dataset\")\n",
    "ax.legend()\n",
    "for n_epoch, n_iter, vv in vv_iter:\n",
    "\n",
    "    pca = PCA()\n",
    "    pca.fit(vv)\n",
    "    yy = pca.explained_variance_\n",
    "    log_yy = np.log(yy)\n",
    "    m, c = np.linalg.lstsq(np.vstack([log_xx, np.ones(len(log_xx))]).T, log_yy, rcond=None)[0]\n",
    "    pcm = ax.plot(xx, yy, '.-', color=cm.viridis(n_epoch / conf.n_epoch))\n",
    "    # ax.legend()\n",
    "    ax.grid(visible=True)\n",
    "    writer.add_figure(f\"{model.__class__.__name__}/{str(conf)}/neuron_fireings\", fig, global_step=n_iter)\n",
    "\n",
    "    v_recon = model(sample_images.view(conf.batch_size, -1).to(device))\n",
    "    sample_recon = make_grid(v_recon.view(conf.batch_size, 3, 32, 32).data).cpu()\n",
    "    writer.add_image(f\"{model.__class__.__name__}/{str(conf)}/sample_input\", sample_img, global_step=n_iter)\n",
    "    writer.add_image(f\"{model.__class__.__name__}/{str(conf)}/sample_recon\", sample_recon, global_step=n_iter)\n",
    "#ax.legend()\n",
    "#fig.colorbar(ax)\n",
    "ax.grid(visible=True)\n",
    "writer.add_figure(f\"{model.__class__.__name__}/{str(conf)}/neuron_fireings\", fig)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25554aa828a01445f449ceb07a62b018f5dc6eacf1fdadcd1881e8950d47054e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
